{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPf+xA+gRH9tjcHWbxuhHVV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coutAYUSH/simple_calculator/blob/main/NLP1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File start\n"
      ],
      "metadata": {
        "id": "DGQLFpGdvbRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiHCl65y6Y1k",
        "outputId": "33cb4f85-1db2-4cfb-9de6-a6e390be968a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "data1 = \"This is natural language processing \"\n",
        "arr = []\n",
        "arr = word_tokenize(data1)\n",
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqvkjEpJTM2w",
        "outputId": "b404b7f4-8841-4bf1-c8e8-dcddba273c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'natural', 'language', 'processing']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "data2 = \"Natural Language Processing (NLP) is a fascinating field of Artificial Intelligence. It enables machines to understand, interpret, and generate human language. Today, NLP powers chatbots, translation apps, and even voice assistants like Siri and Alexa.\"\n",
        "arr1 = []\n",
        "arr1 = sent_tokenize(data2)\n",
        "arr1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2XJiZR0Ulls",
        "outputId": "6f986853-85ae-4897-e0ac-0c212d2de36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural Language Processing (NLP) is a fascinating field of Artificial Intelligence.',\n",
              " 'It enables machines to understand, interpret, and generate human language.',\n",
              " 'Today, NLP powers chatbots, translation apps, and even voice assistants like Siri and Alexa.']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6Ia_BeFVVDZ",
        "outputId": "e847192e-239c-45ae-c62c-326fbd634aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "from nltk import word_tokenize\n",
        "\n",
        "data3 = \"Artificial Intelligence is transforming the world at an incredible pace. From personalized recommendations to self-driving cars, technology is making everyday life more efficient and convenient.\"\n",
        "tokens = word_tokenize(data3)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "pos_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BggsG_OBWVle",
        "outputId": "bdb59003-fab9-4042-ec8d-523ab5f4989d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Artificial', 'JJ'),\n",
              " ('Intelligence', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('transforming', 'VBG'),\n",
              " ('the', 'DT'),\n",
              " ('world', 'NN'),\n",
              " ('at', 'IN'),\n",
              " ('an', 'DT'),\n",
              " ('incredible', 'JJ'),\n",
              " ('pace', 'NN'),\n",
              " ('.', '.'),\n",
              " ('From', 'IN'),\n",
              " ('personalized', 'JJ'),\n",
              " ('recommendations', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('self-driving', 'JJ'),\n",
              " ('cars', 'NNS'),\n",
              " (',', ','),\n",
              " ('technology', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('making', 'VBG'),\n",
              " ('everyday', 'JJ'),\n",
              " ('life', 'NN'),\n",
              " ('more', 'RBR'),\n",
              " ('efficient', 'JJ'),\n",
              " ('and', 'CC'),\n",
              " ('convenient', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "data4 = \"Natural Language Processing (NLP) is a fascinating field of Artificial Intelligence. It enables machines to understand, interpret, and generate human language. Today, NLP powers chatbots, translation apps, and even voice assistants like Siri and Alexa.\"\n",
        "\n",
        "doc = nlp(data4)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5yN6pseXSMW",
        "outputId": "c7c0ccc1-5e95-4ced-c418-bd776e42adb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "Natural Language Processing ORG\n",
            "NLP ORG\n",
            "Artificial Intelligence ORG\n",
            "Today DATE\n",
            "NLP ORG\n",
            "Alexa ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "58MQ-65gXRbb",
        "outputId": "fb387506-d8ae-4941-a034-9570df7418fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Natural Language Processing\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " (\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    NLP\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ") is a fascinating field of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Artificial Intelligence\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ". It enables machines to understand, interpret, and generate human language. \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Today\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    NLP\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " powers chatbots, translation apps, and even voice assistants like Siri and \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Alexa\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "text = \"I love natural language processing and I love learning NLP.\"\n",
        "\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "bigrams = ngrams(tokens, 2)\n",
        "trigrams = ngrams(tokens, 3)\n",
        "\n",
        "bigram_freq = Counter(bigrams)\n",
        "trigram_freq = Counter(trigrams)\n",
        "\n",
        "print(\"Bigrams:\")\n",
        "for bigram, freq in bigram_freq.items():\n",
        "    print(bigram, freq)\n",
        "\n",
        "print(\"\\nTrigrams:\")\n",
        "for trigram, freq in trigram_freq.items():\n",
        "    print(trigram, freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po_z086UcPLM",
        "outputId": "3a845714-6c71-4fa1-876e-3d0e6f4dba5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "Bigrams:\n",
            "('i', 'love') 2\n",
            "('love', 'natural') 1\n",
            "('natural', 'language') 1\n",
            "('language', 'processing') 1\n",
            "('processing', 'and') 1\n",
            "('and', 'i') 1\n",
            "('love', 'learning') 1\n",
            "('learning', 'nlp') 1\n",
            "('nlp', '.') 1\n",
            "\n",
            "Trigrams:\n",
            "('i', 'love', 'natural') 1\n",
            "('love', 'natural', 'language') 1\n",
            "('natural', 'language', 'processing') 1\n",
            "('language', 'processing', 'and') 1\n",
            "('processing', 'and', 'i') 1\n",
            "('and', 'i', 'love') 1\n",
            "('i', 'love', 'learning') 1\n",
            "('love', 'learning', 'nlp') 1\n",
            "('learning', 'nlp', '.') 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "data = np.array(['I', 'love', 'NLP']).reshape(-1,1)\n",
        "encoder = OneHotEncoder(sparse_output= False)\n",
        "encoded_data = encoder.fit_transform(data)\n",
        "\n",
        "encoded_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwGFf2yo6oFN",
        "outputId": "228daca4-6594-4da8-bbc2-c7edc6598bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp2P5E3J-2f6",
        "outputId": "5b6b2bd4-1530-42ad-e32b-523accd94eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "document = [\n",
        "    \"NLP is fun!\",\n",
        "    \"I love learning NLP!\"\n",
        "]\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "def preprocess(text):\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  clean_tokens = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
        "  return clean_tokens\n",
        "\n",
        "tokenized_docs = [preprocess(text) for text in document]\n",
        "\n",
        "all_words = [word for sent in tokenized_docs for word in sent]\n",
        "\n",
        "vocab = sorted(set(all_words))\n",
        "\n",
        "print(\"vocabulary\" , vocab)\n",
        "\n",
        "def bow_vector(token, vocab):\n",
        "  word_freq = Counter(token)\n",
        "  vector = []\n",
        "  for word in vocab:\n",
        "    vector.append(word_freq[word])\n",
        "  return vector\n",
        "\n",
        "bow_vectors = [bow_vector(token, vocab) for token in tokenized_docs]\n",
        "bow_vectors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QlPL4X_8xTM",
        "outputId": "e5046e4a-0f1f-4c26-8aab-c000c29588c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "vocabulary ['fun', 'learning', 'love', 'nlp']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 1], [0, 1, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOMR-Q3ZC5sX",
        "outputId": "87a0102c-2caa-416c-daf8-356d83c261e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "sentence = \" I went to the bank to deposit the money \"\n",
        "word = \"bank\"\n",
        "\n",
        "token = word_tokenize(sentence)\n",
        "sense = lesk(token, word)\n",
        "\n",
        "print(\"Best sense:\", sense)\n",
        "print(\"Definition:\", sense.definition() if sense else \"No sense found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdrAYy8SDe0s",
        "outputId": "2c738b4f-26e4-421d-feba-602915857b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "Best sense: Synset('savings_bank.n.02')\n",
            "Definition: a container (usually with a slot in the top) for keeping money at home\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nHfH0V_EgI_",
        "outputId": "c2cc35a0-2cf8-41f0-adf2-f0a9fe67e31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "text = \"I really love this product! It's amazing and easy to use.\"\n",
        "\n",
        "scores = analyzer.polarity_scores(text)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOqKuNT5FmSZ",
        "outputId": "6e41c042-4bee-4aeb-967e-e4d99aa89d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "{'neg': 0.0, 'neu': 0.379, 'pos': 0.621, 'compound': 0.9097}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"I love machine learning\",\n",
        "    \"Machine learning is fun\",\n",
        "    \"I love coding in Python\"\n",
        "]\n",
        "\n",
        "# Create TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get feature names (vocabulary)\n",
        "words = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert to dense matrix and display\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(tfidf_matrix.toarray(), columns=words)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJCU5OcxGM0O",
        "outputId": "4979c4b9-abfd-46f9-94bb-d41adbe571f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "     coding       fun        in        is  learning     love   machine  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.577350  0.57735  0.577350   \n",
            "1  0.000000  0.562829  0.000000  0.562829  0.428046  0.00000  0.428046   \n",
            "2  0.528635  0.000000  0.528635  0.000000  0.000000  0.40204  0.000000   \n",
            "\n",
            "     python  \n",
            "0  0.000000  \n",
            "1  0.000000  \n",
            "2  0.528635  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "\n",
        "knowledge_base = {\n",
        "    \"what is your name\": \"I am a rule-based chatbot.\",\n",
        "    \"how are you\": \"I'm just a bunch of code, but thanks for asking!\",\n",
        "    \"what is python\": \"Python is a popular programming language.\",\n",
        "    \"who developed python\": \"Python was created by Guido van Rossum.\",\n",
        "    \"what is nlp\": \"NLP stands for Natural Language Processing.\"\n",
        "}\n",
        "\n",
        "\n",
        "def answer_question(question):\n",
        "    question = question.lower().strip()\n",
        "\n",
        "    for key in knowledge_base:\n",
        "        if key in question:\n",
        "            return knowledge_base[key]\n",
        "\n",
        "    return \"I'm sorry, I don't know the answer to that question.\"\n",
        "\n",
        "\n",
        "\n",
        "print(answer_question(\"What is Python?\"))\n",
        "print(answer_question(\"Who developed Python?\"))\n",
        "print(answer_question(\"Tell me about NLP.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdvYK44Cq74b",
        "outputId": "844a4177-545f-4f6e-e609-8500d523fd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "Python is a popular programming language.\n",
            "Python was created by Guido van Rossum.\n",
            "I'm sorry, I don't know the answer to that question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "\n",
        "dictionary = {\n",
        "    \"i\": \"मैं\",\n",
        "    \"you\": \"तुम\",\n",
        "    \"he\": \"वह\",\n",
        "    \"she\": \"वह\",\n",
        "    \"am\": \"हूँ\",\n",
        "    \"are\": \"हो\",\n",
        "    \"is\": \"है\",\n",
        "    \"hungry\": \"भूखा\",\n",
        "    \"happy\": \"खुश\",\n",
        "    \"sad\": \"उदास\",\n",
        "    \"today\": \"आज\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def translate(sentence):\n",
        "    words = sentence.lower().strip().split()\n",
        "    translated = []\n",
        "\n",
        "    for word in words:\n",
        "        if word in dictionary:\n",
        "            translated.append(dictionary[word])\n",
        "        else:\n",
        "            translated.append(f\"[{word}]\")  # unknown word\n",
        "\n",
        "    return ' '.join(translated)\n",
        "\n",
        "\n",
        "print(translate(\"I am happy\"))\n",
        "print(translate(\"You are sad today\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0bJXP-arXFt",
        "outputId": "67fe5338-951e-457e-ec58-4b24679f89f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "मैं हूँ खुश\n",
            "तुम हो उदास आज\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "\n",
        "\n",
        "parallel_corpus = [\n",
        "    (\"मैं खुश हूँ\", \"I am happy\"),\n",
        "    (\"तुम उदास हो\", \"You are sad\"),\n",
        "    (\"वह स्कूल गया\", \"He went to school\"),\n",
        "]\n",
        "\n",
        "phrase_table = {\n",
        "    \"मैं\": \"I\",\n",
        "    \"खुश हूँ\": \"am happy\",\n",
        "    \"तुम\": \"You\",\n",
        "    \"उदास हो\": \"are sad\",\n",
        "    \"वह\": \"He\",\n",
        "    \"स्कूल गया\": \"went to school\"\n",
        "}\n",
        "\n",
        "\n",
        "def translate_smt(hindi_sentence):\n",
        "    words = hindi_sentence.strip().split()\n",
        "    translation = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        # Try to match 2-word phrases\n",
        "        if i+1 < len(words) and f\"{words[i]} {words[i+1]}\" in phrase_table:\n",
        "            translation.append(phrase_table[f\"{words[i]} {words[i+1]}\"])\n",
        "            i += 2\n",
        "        elif words[i] in phrase_table:\n",
        "            translation.append(phrase_table[words[i]])\n",
        "            i += 1\n",
        "        else:\n",
        "            translation.append(f\"[{words[i]}]\")  # unknown word\n",
        "            i += 1\n",
        "\n",
        "    return ' '.join(translation)\n",
        "\n",
        "\n",
        "\n",
        "print(translate_smt(\"मैं खुश हूँ\"))       # Output: I am happy\n",
        "print(translate_smt(\"तुम उदास हो\"))       # Output: You are sad\n",
        "print(translate_smt(\"वह स्कूल गया\"))       # Output: He went to school"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6axIFaJlr2rV",
        "outputId": "15cc30a9-bfca-4302-b3ea-2655005bce5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "I am happy\n",
            "You are sad\n",
            "He went to school\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "suffix_rules = {\n",
        "    \"ing\": \"present participle\",\n",
        "    \"ed\": \"past tense\",\n",
        "    \"s\": \"plural or 3rd person singular\",\n",
        "    \"es\": \"plural or 3rd person singular\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def analyze_word(word):\n",
        "    for suffix in sorted(suffix_rules, key=lambda x: -len(x)):  # longest match first\n",
        "        if word.endswith(suffix):\n",
        "            root = word[:-len(suffix)]\n",
        "            return {\n",
        "                \"original\": word,\n",
        "                \"root\": root,\n",
        "                \"suffix\": suffix,\n",
        "                \"tense/number\": suffix_rules[suffix]\n",
        "            }\n",
        "    return {\n",
        "        \"original\": word,\n",
        "        \"root\": word,\n",
        "        \"suffix\": None,\n",
        "        \"tense/number\": \"unknown\"\n",
        "    }\n",
        "\n",
        "\n",
        "words = [\"playing\", \"played\", \"plays\", \"runs\", \"walked\"]\n",
        "\n",
        "for word in words:\n",
        "    result = analyze_word(word)\n",
        "    print(result)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G82lvckHse3M",
        "outputId": "8e6f4dbd-147b-4443-f9b3-3bb23440a704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "{'original': 'playing', 'root': 'play', 'suffix': 'ing', 'tense/number': 'present participle'}\n",
            "{'original': 'played', 'root': 'play', 'suffix': 'ed', 'tense/number': 'past tense'}\n",
            "{'original': 'plays', 'root': 'play', 'suffix': 's', 'tense/number': 'plural or 3rd person singular'}\n",
            "{'original': 'runs', 'root': 'run', 'suffix': 's', 'tense/number': 'plural or 3rd person singular'}\n",
            "{'original': 'walked', 'root': 'walk', 'suffix': 'ed', 'tense/number': 'past tense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "\n",
        "male_words = [\"he\", \"him\", \"man\", \"male\", \"boy\"]\n",
        "female_words = [\"she\", \"her\", \"woman\", \"female\", \"girl\"]\n",
        "professions = [\"nurse\", \"engineer\", \"teacher\", \"doctor\", \"scientist\", \"receptionist\"]\n",
        "\n",
        "\n",
        "bias_map = {\n",
        "    \"nurse\": \"female\",\n",
        "    \"engineer\": \"male\",\n",
        "    \"teacher\": \"female\",\n",
        "    \"doctor\": \"male\",\n",
        "    \"scientist\": \"male\",\n",
        "    \"receptionist\": \"female\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def simple_bias_check():\n",
        "    print(\"Gender Bias in Professions (Simulated Example):\\n\")\n",
        "    for job in professions:\n",
        "        bias = bias_map.get(job, \"neutral\")\n",
        "        print(f\"{job.title():<15} → Biased toward: {bias}\")\n",
        "\n",
        "\n",
        "simple_bias_check()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow3VcANmtf3_",
        "outputId": "aa75ae8b-6ac2-44db-8f41-0866917798f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "Gender Bias in Professions (Simulated Example):\n",
            "\n",
            "Nurse           → Biased toward: female\n",
            "Engineer        → Biased toward: male\n",
            "Teacher         → Biased toward: female\n",
            "Doctor          → Biased toward: male\n",
            "Scientist       → Biased toward: male\n",
            "Receptionist    → Biased toward: female\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22scse1010380 Ayush Kumar\")\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "resume_text = \"\"\"\n",
        "John Doe\n",
        "Email: john.doe@example.com\n",
        "Phone: +1-555-123-4567\n",
        "\n",
        "Skills:\n",
        "- Python\n",
        "- Machine Learning\n",
        "- Data Analysis\n",
        "- NLP\n",
        "\"\"\"\n",
        "\n",
        "def parse_resume(text):\n",
        "    # Extract Name (assuming it's the first line)\n",
        "    name = text.strip().split('\\n')[0]\n",
        "\n",
        "    # Extract Email\n",
        "    email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
        "    email = email_match.group(0) if email_match else None\n",
        "\n",
        "    # Extract Phone Number (simple pattern)\n",
        "    phone_match = re.search(r'\\+?\\d[\\d\\-\\s]{7,}\\d', text)\n",
        "    phone = phone_match.group(0) if phone_match else None\n",
        "\n",
        "    # Extract Skills (after \"Skills:\" line)\n",
        "    skills = []\n",
        "    skills_section = re.search(r'Skills:(.*)', text, re.DOTALL)\n",
        "    if skills_section:\n",
        "        skills_text = skills_section.group(1)\n",
        "        skills = re.findall(r'-\\s*(.+)', skills_text)\n",
        "\n",
        "    return {\n",
        "        'Name': name,\n",
        "        'Email': email,\n",
        "        'Phone': phone,\n",
        "        'Skills': skills\n",
        "    }\n",
        "\n",
        "parsed = parse_resume(resume_text)\n",
        "print(parsed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUqqIjSUut2i",
        "outputId": "502e0622-6404-4430-deb6-faac2ad8c442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22scse1010380 Ayush Kumar\n",
            "{'Name': 'John Doe', 'Email': 'john.doe@example.com', 'Phone': '+1-555-123-4567', 'Skills': ['Python', 'Machine Learning', 'Data Analysis', 'NLP']}\n"
          ]
        }
      ]
    }
  ]
}